{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFDevSummit18\n",
    "\n",
    "<!-- ![nn](./assets/NN.PNG)-->\n",
    "<img src=\"./TFDevSummit.png\" width=300px>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New resources: \n",
    "-\tBlog.tensorflow.org \n",
    "-\tYoutube.com/tensorflow\n",
    "-\tTensorflow hub \n",
    "-\tMachine Learning Crash Course! \n",
    "-\tGithub.com/tensorflow/tpu – TPU Pod \n",
    "-\tCloud AUTOML\n",
    "-   www.engineeringchallenges.org/chalenges.aspx\n",
    "-   www.tensorflow.org/performance/datasets_performance\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "* 12:54 - Keynote (TensorFlow Dev Summit 2018) \n",
    "* 47:32 - tf. data: Fast, flexible, and easy-to-use input pipelines (TensorFlow Dev Summit 2018) \n",
    "* 1:02:24 - Eager Execution (TensorFlow Dev Summit 2018) \n",
    "* 1:21:32 - Machine Learning in JavaScript (TensorFlow Dev Summit 2018) \n",
    "* 2:11:32 - Training Performance: A user’s guide to converge faster (TensorFlow Dev Summit 2018) \n",
    "* 2:40:50 - The Practitioner's Guide with TF High Level APIs (TensorFlow Dev Summit 2018) \n",
    "* 3:00:30 - Distributed TensorFlow (TensorFlow Dev Summit 2018) \n",
    "* 3:12:26 - Debugging TensorFlow with TensorBoard plugins (TensorFlow Dev Summit 2018) \n",
    "* 4:41:09 - TensorFlow Lite (TensorFlow Dev Summit 2018) \n",
    "* 5:00:10 - Searching Over Ideas (TensorFlow Dev Summit 2018) \n",
    "* 5:15:33 - Reconstructing Fusion Plasmas (TensorFlow Dev Summit 2018) \n",
    "* 5:26:16 - Nucleus: TensorFlow toolkit for Genomics (TensorFlow Dev Summit 2018) \n",
    "* 5:35:55 - Open Source Collaboration (TensorFlow Dev Summit 2018) \n",
    "* 5:45:50 - TFiwS Compiler (TensorFlow Dev Summit 2018) \n",
    "* 6:33:38 - TensorFlow Hub (TensorFlow Dev Summit 2018) \n",
    "* 6:46:31 - TensorFlow Extended (TFX) (TensorFlow Dev Summit 2018) \n",
    "* 7:12:07 - Case Study: Applied AI at The Coca-Cola Company (TensorFlow Dev Summit 2018) \n",
    "* 7:22:28 - Real-World Robot Learning (TensorFlow Dev Summit 2018) \n",
    "* 7:32:10 - Project Magenta (TensorFlow Dev Summit 2018)﻿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keynote : talks and demos; Machine Learning: TENSORFLOW\n",
    "* Astronomy – small dark objects, kepler90i discovery by machine learning \n",
    "* Health care – looking at human eye -> cardio vascular diseases. \n",
    "* Aviation – trajectory prediction, predict BE,DE,NE\n",
    "* Dairy farming – ML health cows, \n",
    "* Climate change – real time detection of cutting of trees – protecting rain forest\n",
    "* Music – ML, DL, new sounds\n",
    "* Culture – lost twin, \n",
    "Last two years – TF easy to use, high level APIs, Eager Execution, contributions... 1,400+\n",
    "Keras integration ... multiple GPUS, clusters... \n",
    "Tensorflow Lite – mobile apps... <br>\n",
    "Many languages ... python, c++, go, java, R, Julia, C#, Haskell, Swift and JS!!!! \n",
    "### 27:00 – Platforms and Performance by Megan Kacholia \n",
    "Independent on the HW... Tensorflow Lite! \n",
    "### TF Lite Performance \n",
    "3x inferencece speedup on MobilNet and InceptionV3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### TF Data \n",
    "49:00 Derek Murray @mrry : <br>\n",
    "tf.data mision - fast, flexibillity, easy to use <br>\n",
    "ETL Extract, Transform, Load <br>\n",
    "\n",
    "* performance guide in tensroflow.org\n",
    "    * www.tensorflow.org/performance/datasets_performance\n",
    "    * new tf.contrib.data.prefetch_to_device() for GPUs in 1.8 <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# run multiple files in parallel: standard PIPELINE...\n",
    "### Extraction\n",
    "NUM_EPOCHS = 100\n",
    "file_pattern = 'XXX'\n",
    "files = tf.data.Dataset.list_files(file_pattern)\n",
    "dataset = tf.data.TFRecordDataset(files)\n",
    "### Transformation\n",
    "dataset = dataset.suffle(1000)\n",
    "dataset = dataset.repeat(NUM_EPOCHS)\n",
    "dataset = dataset.map(lambda x: tf.parse_single_example(x,feautres))\n",
    "### Load\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "features = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### Extraction improvements FAST\n",
    "files = tf.data.Dataset.list_files(file_pattern)\n",
    "dataset = tf.data.TFRecordDataset(files, num_parallel_reads=32)\n",
    "### Transformation improvements\n",
    "dataset = dataset.apply(tf.contrib.data.shuffle_and_repeat(1000, NUM_EPOCHS))\n",
    "dataset = dataset.apply(tf.contrib.data.map_and_batch(lambda x: ... , BATCH_SIZE))\n",
    "### Load improvements\n",
    "dataset = dataset.apply(tf.contrib.data.prefetch_to_device(\"/gpu:0\"))\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "features = iterator.get_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# improvements - Flexibillity \n",
    "Dataset.map\n",
    "tf.SparseTensor\n",
    "Dataset.from_generator()\n",
    "#Easy of use ... eager execution: \n",
    "# it makes the dataset a normal python iterable\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "    files = tf.data.Dataset.list_files(file_pattern)\n",
    "    dataset = tf.data.TFRecordD \n",
    "    ...\n",
    "or \n",
    "    dataset = tf.contrib.data.make_csv_dataset(\"*.csv\", BATCH_SIZE, num_epochs=NUM_EPCOHS)\n",
    "    \n",
    "\n",
    "for batch in dataset: \n",
    "        train_model(batch)\n",
    "        \n",
    "# standard examples for CSV and data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Simple example: KAGGLE API \n",
    "# $ pip install kaggle\n",
    "# $ kaggle datasets download -d therohk/million-headlines -p\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "dataset = tf.contrib.data.make_csv_dataset(\"*.csv\", BATCH_SIZE, num_epochs=NUM_EPCOHS)\n",
    "for batch in dataset: \n",
    "        train_model(batch[\"publish_date\"], batch[\"headline_text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Wrap the dataset in an input function, and return it directly \n",
    "def input_fn()\n",
    "    dataset = tf.contrib.data.make_csv_dataset(\"*.csv\", BATCH_SIZE, num_epochs = NUM_EPOCHS)\n",
    "    return dataset\n",
    "# train stimator on the dataset \n",
    "tf.estimator.Estimator(model_fn=train_model).train(input_fn=input_fn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 1:02 - Alex eager execution\n",
    "Alex Passos <br>\n",
    "Graphs before because: platform independent graph! - differenciation, easy deployment python server, phone. Compilers kernel funsion, distribution in 100 machines. \n",
    "<br>\n",
    "why eager execution? - more flexibillit, productivity, debugging \n",
    "\n",
    "##### resources: \n",
    "* live demo: goo.gl/eRpP8j\n",
    "* getting started guide: www.tensorflow.org/programmers_guide/eager\n",
    "* browse example models: goo.gl/RTHJa5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[16. 21.]\n",
      " [28. 37.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# easy to use\n",
    "a = tf.constant([[2.0, 3.0],[4.0,5.0]])\n",
    "print(tf.matmul(a,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dynamic control flow\n",
    "def line_search_step(f, init_x, rate=1.0):\n",
    "    with tf.GradientTape() as t: \n",
    "        tape.watch(init_x)\n",
    "        value = f(init_x)\n",
    "    grad, = tf.gradient(value, init_x)\n",
    "    grad_norm = tf.reduce_sum(grad * grad)\n",
    "    init_value = value \n",
    "    while value > init_value - rate * grad_norm: \n",
    "        x = init_x - rate * grad\n",
    "        value = f(x)\n",
    "        rate /= 2.0\n",
    "\n",
    "    return x, value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# new symbols: \n",
    "# import tensorflow as tf \n",
    "import tensorflow.contrib.eager as tfe \n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: id=26, shape=(1, 1), dtype=float32, numpy=array([[2.]], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "w = tfe.Variable([[1.0]])\n",
    "with tf.GradientTape() as tape:\n",
    "    loss = w*w # hopefully your is smarter \n",
    "#     import pdb; pdb.set_tace() # debugging \n",
    "    \n",
    "# dw = tf.gradients(loss, [w])\n",
    "dw = tape.gradient(loss, [w])\n",
    "print(dw) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  5 10:59:11 2018    prof\n",
      "\n",
      "         5566 function calls in 4.031 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    4.031    4.031 {built-in method builtins.exec}\n",
      "        1    0.000    0.000    4.031    4.031 <string>:1(<module>)\n",
      "        1    0.063    0.063    4.031    4.031 <ipython-input-15-bd1ebe5a78b3>:3(my_model)\n",
      "      202    3.949    0.020    3.949    0.020 {built-in method _pywrap_tensorflow_internal.TFE_Py_FastPathExecute}\n",
      "      100    0.003    0.000    3.824    0.038 math_ops.py:1944(matmul)\n",
      "      100    0.001    0.000    3.817    0.038 gen_math_ops.py:4246(mat_mul)\n",
      "      100    0.003    0.000    0.137    0.001 math_ops.py:966(binary_op_wrapper)\n",
      "      100    0.001    0.000    0.130    0.001 gen_math_ops.py:279(add)\n",
      "        2    0.000    0.000    0.007    0.003 array_ops.py:1579(zeros)\n",
      "        2    0.000    0.000    0.004    0.002 gen_array_ops.py:2687(fill)\n",
      "        2    0.000    0.000    0.002    0.001 array_ops.py:1569(_constant_if_small)\n",
      "        2    0.000    0.000    0.002    0.001 fromnumeric.py:2456(prod)\n",
      "        2    0.000    0.000    0.002    0.001 _methods.py:34(_prod)\n",
      "        2    0.002    0.001    0.002    0.001 {method 'reduce' of 'numpy.ufunc' objects}\n",
      "      202    0.001    0.000    0.002    0.000 ops.py:5987(__exit__)\n",
      "      202    0.001    0.000    0.002    0.000 ops.py:5922(__init__)\n",
      "      202    0.001    0.000    0.002    0.000 ops.py:5936(__enter__)\n",
      "      404    0.001    0.000    0.001    0.000 context.py:319(scope_name)\n",
      "      302    0.001    0.000    0.001    0.000 ops.py:717(dtype)\n",
      "      206    0.000    0.000    0.001    0.000 dtypes.py:269(__eq__)\n",
      "      100    0.000    0.000    0.001    0.000 ops.py:959(convert_to_tensor)\n",
      "      633    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "      100    0.000    0.000    0.000    0.000 ops.py:1021(internal_convert_to_tensor)\n",
      "      406    0.000    0.000    0.000    0.000 context.py:302(executing_eagerly)\n",
      "      202    0.000    0.000    0.000    0.000 {method '_shape_tuple' of 'EagerTensor' objects}\n",
      "      104    0.000    0.000    0.000    0.000 dtypes.py:102(base_dtype)\n",
      "      208    0.000    0.000    0.000    0.000 dtypes.py:652(as_dtype)\n",
      "      406    0.000    0.000    0.000    0.000 context.py:567(context_safe)\n",
      "      100    0.000    0.000    0.000    0.000 context.py:594(executing_eagerly)\n",
      "      402    0.000    0.000    0.000    0.000 context.py:314(scope_name)\n",
      "      302    0.000    0.000    0.000    0.000 {method '_datatype_enum' of 'EagerTensor' objects}\n",
      "        4    0.000    0.000    0.000    0.000 constant_op.py:134(constant)\n",
      "        2    0.000    0.000    0.000    0.000 constant_op.py:248(_tensor_shape_tensor_conversion_function)\n",
      "      104    0.000    0.000    0.000    0.000 dtypes.py:89(_is_ref_dtype)\n",
      "      210    0.000    0.000    0.000    0.000 dtypes.py:134(as_datatype_enum)\n",
      "        4    0.000    0.000    0.000    0.000 constant_op.py:89(convert_to_eager_tensor)\n",
      "      100    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "        2    0.000    0.000    0.000    0.000 tensor_shape.py:503(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 tensor_shape.py:538(<listcomp>)\n",
      "        3    0.000    0.000    0.000    0.000 tensor_shape.py:463(as_dimension)\n",
      "        2    0.000    0.000    0.000    0.000 tensor_shape.py:876(is_fully_defined)\n",
      "        3    0.000    0.000    0.000    0.000 tensor_shape.py:30(__init__)\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        5    0.000    0.000    0.000    0.000 tensor_shape.py:878(<genexpr>)\n",
      "        2    0.000    0.000    0.000    0.000 tensor_shape.py:890(as_list)\n",
      "        4    0.000    0.000    0.000    0.000 context.py:253(_handle)\n",
      "        2    0.000    0.000    0.000    0.000 {method 'get' of 'dict' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        2    0.000    0.000    0.000    0.000 context.py:306(scalar_cache)\n",
      "        6    0.000    0.000    0.000    0.000 tensor_shape.py:83(value)\n",
      "        2    0.000    0.000    0.000    0.000 tensor_shape.py:901(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 context.py:334(device_name)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pstats.Stats at 0x11c4920b8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# measure performance in a program: \n",
    "import cProfile\n",
    "def my_model(): \n",
    "    w = tf.zeros([1000, 1000])\n",
    "    b = tf.zeros([1000])\n",
    "    for _ in range(100):\n",
    "        w = tf.matmul(w,w)\n",
    "        w += b\n",
    "cProfile.run('my_model()', 'prof')\n",
    "import pstats\n",
    "p = pstats.Stats('prof')\n",
    "p.strip_dirs().sort_stats('cumulative').print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# NEW APIs\n",
    "## Customizing gradients\n",
    "@tf.custom_gradient\n",
    "def clip_gradient_by_norm(x, norm):\n",
    "    y = tf.identity(x)\n",
    "    def grad_fn(dresult):\n",
    "        return [tf.clip_by_norm(dresult, norm), None]\n",
    "    return y, grad_fn\n",
    "\n",
    "## Variables are objects \n",
    "with tf.device(\"gpu:0\"):\n",
    "    v = tfe.Variable(tf.random_normal([1000, 1000]))\n",
    "    v = None # now v no longer takes up GPU memory \n",
    "    # dont' worry about memory scope ... \n",
    "    \n",
    "## Object Oriented metrics\n",
    "m = tfe.metrics.Mean(\"my_metric\")\n",
    "m([2])\n",
    "m([8])\n",
    "m.result() #5.0\n",
    "\n",
    "## Object-based saving \n",
    "model = MyModel()\n",
    "optimizer = tf.AdamOptimizer(0.001)\n",
    "checkpoint_directory = '/home/dvtir/my_model'\n",
    "checkpoint_prefix = os.path.join(checkpoint_directory, \"ckpt\")\n",
    "root = tfe.Checkpoint(\n",
    "            optimizer = optimizer, model = model, \n",
    "            optimizer_step = tf.train.get_or_create_global_step())\n",
    "root.restore(tf.train.latest_checkpoint(checkpoint_directory))\n",
    "#or\n",
    "root.save(file_prefix = checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# as fast as tensroflow ... \n",
    "\n",
    "# interoperating with graphs \n",
    "# tfe.make_template = call graphs from eager\n",
    "def apply_resnet(x): \n",
    "    return resnet50.Resnet50(x)\n",
    "\n",
    "t = tfe.make_template(\"f\", apply_resnet, create_graph_function=True)\n",
    "print(t(image)) # RUN ith GRAPHS\n",
    "\n",
    "# tfe.py_func = call eager from graphs\n",
    "def my_py_func(x):\n",
    "    x = tf.matmul(x, x)\n",
    "    print(x) # eager\n",
    "    return x\n",
    "\n",
    "with tf.Session as sess:\n",
    "    x = tf.placeholder(dtype=tf.float32)\n",
    "    # Call eager function in graph! \n",
    "    pf = tfe.py_func(my_py_func, [x])\n",
    "    sess.run(pf, feed_dict={x:[[2.0]]}) #[[4.0]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "compatible code: use boths! wite code that works in both. <br>\n",
    "advise : keras model - layers, <br>\n",
    "* Use tf.keras.layers \n",
    "* tf.keras.Model \n",
    "* tf.contrib.summary \n",
    "* tfe.metrics \n",
    "* use object-based saving! \n",
    "\n",
    "<br>\n",
    "* why to enable eager execution: better for learning! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.20 ML in JS with TF\n",
    "Daniel Smilkov @dsmikov Nikhil Thorat @nsthorat\n",
    "<br>\n",
    "tensorflow playground => Educational success \n",
    "in the browser - no drivers / no installs, interactive, sensors ( camara, microphone, gps ... ) data stays on the client... privacy\n",
    "\n",
    "* deeplearn.js (08.2017) - GPU accelerated with WebGL\n",
    "style transfer in the browser \n",
    "generative model for hidden dimmensions in the font \n",
    "* tensorFlow.js (deeplearn.js into tf) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
